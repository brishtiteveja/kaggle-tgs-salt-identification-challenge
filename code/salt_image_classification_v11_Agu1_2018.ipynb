{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "Seismic data is a neat thing. You can imagine it like an ultra-sound of the subsurface. However, in an ultra-sound, we use much smaller wavelengths to image our body. Seismic data usually has wavelengths around 1m to 100m. That has some physical implications, but for now, we don't have to deal with that. It's just something to keep in mind while thinking about resolution. \n",
    "\n",
    "Imaging salt has been a huge topic in the seismic industry, basically since they imaged salt the first time. The Society of Exploration geophysicist alone has over 10,000 publications with the [keyword salt](https://library.seg.org/action/doSearch?AllField=salt). Salt bodies are important for the hydrocarbon industry, as they usually form nice oil traps. So there's a clear motivation to delineate salt bodies in the subsurface. If you would like to do a deep dive, you can see [this publication](https://www.iongeo.com/content/documents/Resource%20Center/Articles/INT_Imaging_Salt_tutorial_141101.pdf)\n",
    "\n",
    "Seismic data interpreters are used to interpreting on 2D or 3D images that have been heavily processed. The standard work of [seismic data analysis](https://wiki.seg.org/wiki/Seismic_Data_Analysis) is open access.\n",
    "You'll find sections on Salt in there as well (https://wiki.seg.org/wiki/Salt-flank_reflections and https://wiki.seg.org/wiki/Salt_flanks). The seismic itself is pretty \"old\" in the publication, and you're dealing with data that is less noisy here, which is nice.\n",
    "\n",
    "[![Seismic Data with salt CC-BY-SA Yilmaz](https://wiki.seg.org/images/1/14/Ch05_fig0-1.png)](https://wiki.seg.org/wiki/Salt-flank_reflections#/media/File:Ch05_fig0-1.png)\n",
    "Caption: Figure 5.0-1  Conflicting dips associated with salt flanks: (a) CMP stack without dip-moveout correction; (b) time migration of the stack in (a); (c) the stack with dip-moveout correction; (d) time migration of the stack in (c). CC-BY-SA Yilmaz.\n",
    "\n",
    "Interpretation on seismic images has long used texture attributes, to identify better and highlight areas of interest. These can be seen like feature maps on the texture of the seismic. For salt, you will notice that the texture in the salt masks is rather chaotic, where the surrounding seismic is more \"striped\". You can think of Earth as layered. Sand gets deposited on top of existing sand. In comes salt, which is behaving very much, unlike other rocks. There is an entire research branch dedicated to salt tectonics, that is the movement of salt in the subsurface. To give you the gist, these salt diapirs form from salt layers somewhere else that were under much pressure. These started to flow (behave ductile) and find a way into other layers above. I have written a bit about salt on [my blog](http://the-geophysicist.com/the-showroom-data-for-my-thesis).\n",
    "\n",
    "One common seismic attribute is called \"chaos\" or \"seismic disorder\". So if you talk to cynic geophysicists, you'll hear \"that deep learning better outperform the Chaos attribute\". A good starting point is [this publication](http://www.chopraseismic.com/wp-content/uploads/2016/08/Chopra_Marfurt_TLE_Aug2016-LowRes.pdf).\n",
    "\n",
    "Recently, geoscience has started to adopt deep learning, and it has seen a clear boom, particularly in imaging salt. Code for automatic seismic interpretation can be found here: \n",
    "\n",
    "+ https://github.com/waldeland/CNN-for-ASI\n",
    "+ https://github.com/bolgebrygg/MalenoV\n",
    "+ https://github.com/crild/facies_net\n",
    "\n",
    "You will notice that these solutions load a specific SEG-Y file, which luckily we don't have to bother with. TGS provided some nice PNG files instead. However, you can glean some information from them how to approach seismic data. If you find you need some geophysical helpers, you can [import Bruges](https://github.com/agile-geoscience/bruges)\n",
    "\n",
    "Let's dive in for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "00833d394e3069216af171fd979c814e7e1e430d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (hashtable as _hashtable,\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import hashing, tslib\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, index as libindex, tslib as libts,\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.tslibs.offsets as liboffsets\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/core/ops.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as libalgos, ops as libops\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/core/indexes/interval.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs.interval import (\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/core/internals.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import internals as libinternals\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/core/sparse/array.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.sparse as splib\n",
      "/home/azehady/.local/lib/python2.7/site-packages/subprocess32.py:146: RuntimeWarning: The _posixsubprocess module is not being used. Child process reliability may suffer if your program uses threads.\n",
      "  \"program uses threads.\", RuntimeWarning)\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/core/window.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.window as _window\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/core/groupby/groupby.py:68: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, reduction,\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as _algos, reshape as _reshape\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/io/parsers.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.parsers as parsers\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pandas/io/pytables.py:50: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib, writers as libwriters\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/interpolate/_bsplines.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _ni_label\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/signal/_max_len_seq.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._max_len_seq_inner import _max_len_seq_inner\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/signal/_upfirdn.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._upfirdn_apply import _output_len, _apply\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/optimize/_trlib/__init__.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._trlib import TRLIBQuadraticSubproblem\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/optimize/_numdiff.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._group_columns import group_dense, group_sparse\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/signal/spectral.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._spectral import _lombscargle\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/stats/_continuous_distns.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _stats\n",
      "/home/azehady/.local/lib/python2.7/site-packages/scipy/signal/_peak_finding.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._peak_finding_utils import (_argmaxima1d, _select_by_peak_distance,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azehady/.local/lib/python2.7/site-packages/pywt/__init__.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._extensions._pywt import *\n",
      "/home/azehady/.local/lib/python2.7/site-packages/pywt/_swt.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._extensions._swt import swt_max_level, swt as _swt, swt_axis as _swt_axis\n",
      "/home/azehady/.local/lib/python2.7/site-packages/h5py/__init__.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/azehady/.local/lib/python2.7/site-packages/h5py/__init__.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import h5a, h5d, h5ds, h5f, h5fd, h5g, h5r, h5s, h5t, h5p, h5z\n",
      "/home/azehady/.local/lib/python2.7/site-packages/h5py/_hl/group.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .. import h5g, h5i, h5o, h5r, h5t, h5l, h5p\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dropout, Flatten\n",
    "from keras.layers import BatchNormalization,Concatenate\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "0e26e21ff39e8b2afc0003fec4e4f5269f61aa4c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "im_width = 128\n",
    "im_height = 128\n",
    "im_chan = 3\n",
    "path_train = '../input/train/'\n",
    "path_test = '../input/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89455be399a79910334eb76beafc40bcdab08f83"
   },
   "source": [
    "# Data Exploration\n",
    "Let's look at some data. We can see that TGS chose to use very varied data by inspecting. That is great and adresses a problem in deep learning geoscience at the moment. We build models on one type of seismic and have no idea whether it generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2dccf3274ff5ea9bddc430bae092342c871f41ac",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\n",
    "plt.figure(figsize=(20,10))\n",
    "for j, img_name in enumerate(ids):\n",
    "    q = j+1\n",
    "    img = load_img('../input/train/images/' + img_name + '.png')\n",
    "    img_mask = load_img('../input/train/masks/' + img_name + '.png')\n",
    "    \n",
    "    plt.subplot(1,2*(1+len(ids)),q*2-1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2*(1+len(ids)),q*2)\n",
    "    plt.imshow(img_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61fa14e7421411a0ca943a1a36e77cbef2ddcbd2"
   },
   "source": [
    "We have many examples without salt, as you can see by the masks that are entirely dark. That's great, an algorithm we build will then know that patches exist entirely without salt. Talk about biasing your data.\n",
    "\n",
    "We can draw heavily on other work, instead of regurgitating the geophysics work that has been done before. I mentioned that seismic is kind of like ultrasound. So I had a look at https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\n",
    "\n",
    "Let's throw a Unet at our data. I am blatanly stealing from Ketil at this point. All credit goes to him and his nice code.\n",
    "First we'll need to get our data into a shape that works for U-Nets. That means, it should be a power of 2. Let's do it quick and dirty for now, but eventually, consider aliasing and all that fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "97114b7b4f28347130dc3e44af5469d6efdf7ab1",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ids = next(os.walk(path_train+\"images\"))[2]\n",
    "test_ids = next(os.walk(path_test+\"images\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ee3d0fb98094a4a6c5604093c5706a7db96df97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image Data Augmentation\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "# https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
    "# https://towardsdatascience.com/image-augmentation-for-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "a8f02165966489c8a21bb7127bb88e7cf607599d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "R_chan = 0\n",
    "G_chan = 1\n",
    "B_chan = 2\n",
    "\n",
    "X_train_orig_img = [None]\n",
    "X_train_gray_img = [None]\n",
    "X_train_rgb_img = np.zeros((len(train_ids), im_height, im_width, 3), dtype=np.uint8)\n",
    "Y_train_mask_img = np.zeros((len(train_ids), im_height, im_width, 3), dtype=np.uint8)\n",
    "Y_train_orig_mask_img = [None]\n",
    "\n",
    "X_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\n",
    "\n",
    "X_train_new = np.zeros((len(train_ids), im_height, im_width, 3), dtype=np.uint8)\n",
    "Y_train_new = np.zeros((len(train_ids), im_height, im_width, 3), dtype=np.uint8)\n",
    "\n",
    "img_ids = []\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = path_train\n",
    "    img_ids.append(id_)\n",
    "    img = load_img(path + '/images/' + id_ )\n",
    "    \n",
    "#     r_id = random.randint(0, 100)\n",
    "#     id_ = train_ids[r_id]\n",
    "#     print(r_id)\n",
    "#     img = load_img(path + '/images/' + id_ )\n",
    "\n",
    "    x_img = img_to_array(img)\n",
    "    X_train_orig_img.append(x_img)\n",
    "    x_img = resize(x_img, (im_width, im_height, 3), mode='constant', preserve_range=True)\n",
    "    X_train_rgb_img[n] = x_img\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    #X_train_gray_img.append(x)\n",
    "    x = resize(x, (im_width, im_height, 1), mode='constant', preserve_range=True)\n",
    "    X_train[n] = x\n",
    "    mask_img = load_img(path + '/masks/' + id_)\n",
    "    Y_train_orig_mask_img.append(mask_img)\n",
    "    mask = img_to_array(mask_img)\n",
    "    mask_img = resize(mask, (im_width, im_height, 3), mode='constant', preserve_range=True)\n",
    "    Y_train_mask_img[n] = mask_img\n",
    "    Y_train[n] = resize(mask[:,:,1], (im_width, im_height, 1), mode='constant', preserve_range=True)\n",
    "    #res = cv2.bitwise_and(img, img, mask = mask)\n",
    "    \n",
    "    res1 = mask_img * x_img\n",
    "    mask_inv = 255.0 - mask_img\n",
    "    res2 = mask_inv * x_img\n",
    "\n",
    "    for x1 in range(im_width):\n",
    "        for x2 in range(im_height):\n",
    "            if x1 < im_width - 1 and x2 < im_height - 1:\n",
    "                if  res2[x1,x2, R_chan] == 0 and res2[x1,x2, G_chan] == 0 and res2[x1,x2, B_chan] == 0: # when green channel is 0, color with red\n",
    "                    res2[x1,x2, G_chan] = 100\n",
    "                #else:\n",
    "                    #res2[x1, x2, R_chan] = 100\n",
    "                \n",
    "\n",
    "    res3 = res1+res2\n",
    "    res4 = res3 * mask_img\n",
    "    res5 = res2 * mask_img\n",
    "    \n",
    "    X_train_new[n] = res2\n",
    "    Y_train_new[n] = res5\n",
    "    \n",
    "#     break\n",
    "    \n",
    "# plt.subplot(1,5,1)\n",
    "# plt.imshow(res1)\n",
    "# plt.subplot(1,5,2)\n",
    "# plt.imshow(res2)\n",
    "# plt.subplot(1,5,3)\n",
    "# plt.imshow(res3)\n",
    "# plt.subplot(1,5,4)\n",
    "# plt.imshow(res4)\n",
    "# plt.subplot(1,5,5)\n",
    "# plt.imshow(res5)\n",
    "# plt.show()\n",
    "\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(x_img)\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(mask_img)\n",
    "# plt.show()\n",
    "\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(res3)\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(res5)\n",
    "# plt.show()\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "faf6ea42655fb0f5ee8994a65a7c3bef888ef1ae",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "print(X_train[ix].shape)\n",
    "#plt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\n",
    "plt.imshow(X_train_new[ix])\n",
    "plt.show()\n",
    "\n",
    "print(Y_train[ix].shape)\n",
    "tmp = np.squeeze(Y_train_new[ix]).astype(np.float32)\n",
    "#plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.imshow(tmp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d66a11a8d8d48e16640307185062f5494c1f5b6"
   },
   "source": [
    "# Train Model\n",
    "Our task, just like the segmentation task for nuclei, is evaluated on the mean IoU metric. This one isn't in keras, but obviously, we're stealing this one too from Ketil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4716a2112dfb71c75e60bff90cb17836f78bf66",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0e7c423ccf5145d6ac991dad85262540735e4dfe"
   },
   "source": [
    "This is the fun part. Building the sequential Model. The U-Net is basically looking like an Auto-Encoder with shortcuts. \n",
    "\n",
    "We're also sprinkling in some earlystopping to prevent overfitting. If you're running this on kaggle, this is the point, you want to have GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb09cfb0643c3f10e87fbb325821b217da4d9dcf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(m, dim, acti, bn, res, do=0):\n",
    "\tn = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
    "\tn = BatchNormalization()(n) if bn else n\n",
    "\tn = Dropout(do)(n) if do else n\n",
    "\tn = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
    "\tn = BatchNormalization()(n) if bn else n\n",
    "\treturn Concatenate()([m, n]) if res else n\n",
    "\n",
    "def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
    "\tif depth > 0:\n",
    "\t\tn = conv_block(m, dim, acti, bn, res)\n",
    "\t\tm = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
    "\t\tm = level_block(m, int(inc*dim), depth-1, inc, acti, do, bn, mp, up, res)\n",
    "\t\tif up:\n",
    "\t\t\tm = UpSampling2D()(m)\n",
    "\t\t\tm = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
    "\t\telse:\n",
    "\t\t\tm = Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)\n",
    "\t\tn = Concatenate()([n, m])\n",
    "\t\tm = conv_block(n, dim, acti, bn, res)\n",
    "\telse:\n",
    "\t\tm = conv_block(m, dim, acti, bn, res, do) # do dropout for last layer\n",
    "\treturn m\n",
    "\n",
    "def UNet(img_shape, out_ch=1, start_ch=64, depth=4, inc_rate=2., activation='relu', \n",
    "\t\t dropout=0.5, batchnorm=False, maxpool=True, upconv=True, residual=False):\n",
    "\ti = Input(shape=img_shape)\n",
    "\to = level_block(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)\n",
    "\to = Conv2D(out_ch, 1, activation='sigmoid')(o)\n",
    "\treturn Model(inputs=i, outputs=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8fb6dedf8b50a8150c2177f5b2175559e9b9e985",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "#img_shape = (im_height, im_width, im_chan)\n",
    "img_shape = (im_height, im_width, 3)\n",
    "inputs = Input(img_shape)\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "model = UNet(img_shape, out_ch = 3, start_ch=8, depth=4, dropout=0.5, batchnorm=True)\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mean_iou'])\n",
    "model.compile(optimizer='adam', loss=dice_coef_loss, metrics = [dice_coef])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a32ece6c94c69191b26ba8eabfe501cb3480cd6a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train_new.shape)\n",
    "print(Y_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "58969e2e3bdca3b94da4ebd4e513a83455adf00a",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "#checkpointer = ModelCheckpoint('model-tgs-salt-3-dropout-0.5-batchnorm-accuracy.h5', verbose=1, save_best_only=True)\n",
    "checkpointer = ModelCheckpoint('model-tgs-salt-3-dropout-0.5-batchnorm-dice_coef.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train_new, Y_train_new, validation_split=0.1, batch_size=8, epochs=100, \n",
    "                     callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f3ba4fe34672a2c8b4687293861f5ce59e2c26e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = results.history['loss']\n",
    "val_loss = results.history['val_loss']\n",
    "\n",
    "acc = results.history['acc']\n",
    "val_acc = results.history['val_acc']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training vs Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training Acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n",
    "plt.title('Training vs Validation acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07f33fc4ad0abec843770c65831a21e586d88a49",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# val_loss = results.history['val_loss']\n",
    "# val_mean_iou = results.history['val_mean_iou']\n",
    "# mean_iou = results.history['mean_iou']\n",
    "\n",
    "# epochs = range(len(val_loss))\n",
    "\n",
    "# plt.plot(epochs, mean_iou, 'bo', label='Validation Loss')\n",
    "# plt.plot(epochs, val_mean_iou, 'b', label='Validation mean IOU')\n",
    "# plt.title('')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "22c52fa0216935778bad80956dcb3e2342a6909f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = results.history['loss']\n",
    "val_loss = results.history['val_loss']\n",
    "dice_coef = results.history['dice_coef']\n",
    "val_dice_coef = results.history['val_dice_coef']\n",
    "\n",
    "epochs = range(len(val_loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, dice_coef, 'bo', label='Dice Coef')\n",
    "plt.plot(epochs, val_dice_coef, 'b', label='Validation Dice Coef')\n",
    "plt.title('Training vs Validation Dice Coef')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ab8516fb8ab135872dd4f4b895b5d76206df1fa"
   },
   "source": [
    "# Test Data\n",
    "First we'll get the test data. This takes a while, it's 18000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6d376a5ed9fa0ff708299f55a0a8ed8b8471137",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get and resize test images\n",
    "#X_test = np.zeros((len(test_ids), im_height, im_width, 1), dtype=np.uint8)\n",
    "X_test_new = np.zeros((len(test_ids), im_height, im_width, 3), dtype=np.uint8)\n",
    "\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = path_test\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)\n",
    "    x_img = x\n",
    "    x = x[:,:,1]\n",
    "    sizes_test.append([x.shape[0], x.shape[1]])\n",
    "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    x_new = resize(x_img, (128, 128, 3), mode='constant', preserve_range=True)\n",
    "    #X_test[n] = x\n",
    "    X_test_new[n] = x_new\n",
    "\n",
    "print(X_test_new.shape)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2316034edcb7227673fd9b69264ca9c0d0e87f14",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "# Predict on train, val and test\n",
    "#model = load_model('model-tgs-salt-3-dropout-0.5-batchnorm.h5', custom_objects={'mean_iou': mean_iou})\n",
    "#model = load_model('model-tgs-salt-3-dropout-0.5-batchnorm-accuracy.h5')\n",
    "model = load_model('model-tgs-salt-3-dropout-0.5-batchnorm-dice_coef.h5', \n",
    "                   custom_objects={'dice_coef': dice_coef, 'dice_coef_loss': dice_coef_loss})\n",
    "\n",
    "preds_train = model.predict(X_train_new[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train_new[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test_new, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58bc6bef25dabc0a0a833f8c926eb95c0771ad8b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('../working/Outputpreds_test', preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f2edb5ece371531a14c2c188b4cb09f03079b4c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_test_l = np.load('../working/preds_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af64790cdb7e5beb05fc34635cdf092124d7dc20",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del X_train\n",
    "# del X_train_orig_img\n",
    "# del X_train_rgb_img\n",
    "# del X_train_gray_img\n",
    "# del Y_train\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "# preds_test_upsampled = []\n",
    "# for i in tnrange(len(preds_test)):\n",
    "#     preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "#                                        (sizes_test[i][0], sizes_test[i][1]), \n",
    "#                                        mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7da5a47444df98205dd7039223868b5d67f15400",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preds_test_upsampled[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24defa25c00d0d91b38e559515e78c63f4d26e2b"
   },
   "source": [
    "We'll look at it again, just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6302c46fc76d8a43cb87d01c43c60c3c8f0ac98b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Perform a sanity check on some random training samples\n",
    "# ix = random.randint(0, len(preds_train_t))\n",
    "# #plt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\n",
    "# plt.imshow(X_train_new[ix])\n",
    "# plt.show()\n",
    "# # tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
    "# # plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "# plt.imshow(Y_train_new[ix])\n",
    "# plt.show()\n",
    "\n",
    "# tmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\n",
    "# #plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "# plt.imshow(tmp)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "844cded40edc71652bc5b26852245e37f46f6448"
   },
   "source": [
    "# Prepare Submission\n",
    "We need to prepare the submission. A nice CSV with predictions. All of this is one to one from Ketil and does not differ from any of the other segmentation tasks. Check them out to improve on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73336f76166028ba39c8164083c9564a0d5afe40",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n",
    "# pred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm_notebook(enumerate(test_ids))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6eaf7acaf4a0678638c5e40732c6533816777637",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "# sub.index.names = ['id']\n",
    "# sub.columns = ['rle_mask']\n",
    "# sub.to_csv('submission-dropout-0.5-batchnorm-dice-coef.csv')\n",
    "#model-tgs-salt-3-dropout-0.5-batchnorm.h5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
